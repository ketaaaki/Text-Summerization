{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstractive-summarization",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI6-O2fWrBdb"
      },
      "source": [
        "**Installing our dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpgaHGs3slM9"
      },
      "source": [
        "Let's start with installing PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz1_zgEPq60w"
      },
      "source": [
        "!pip3 install torch==1.8.2+cu102 torchvision==0.9.2+cu102 torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDZpKzjRspxA"
      },
      "source": [
        "Our next dependency is HuggingFace transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG1sA-SFsuYP"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DIofQXEv-pr"
      },
      "source": [
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9OjvLgzt0jD"
      },
      "source": [
        "**Importing and configuring the Pegasus model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Eur_UFUt2bh"
      },
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6ZeCd_svj6E"
      },
      "source": [
        "tokenizer_model = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLDu-R1L0vL2"
      },
      "source": [
        "loaded_model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE-stoUN3JGJ"
      },
      "source": [
        "**Performing abstractive summarization **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsGXgLgj3Kxq"
      },
      "source": [
        "text = \"\"\"Hugging Face is a great open-source library that is doing powerful work in the Natural Language Processing (NLP) space. \n",
        "The library has a bunch of pre-trained models which you can leverage or fine-tune. \n",
        "\n",
        "The library has many models including BERT and GPT-2 models that perform various tasks, but for our purpose, weâ€™ll be leveraging the pre-trained language pipeline. \n",
        "Rather than going ahead and training a huge language model such as GPT-2 with 1.5 billion parameters, one can leverage the ML pipeline instead.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSnlUuhb6_l6"
      },
      "source": [
        "tokens = tokenizer_model(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-HOQCQG8d-0"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D760JwCFF9CC"
      },
      "source": [
        "summary = loaded_model.generate(**tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATG_eKp0F2vr"
      },
      "source": [
        "summary[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ9w0Mj6GFaF"
      },
      "source": [
        "## Final summary\n",
        "tokenizer_model.decode(summary[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}